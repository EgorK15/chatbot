import os
import pickle
import json
from typing import Dict, Any, Optional
from sklearn.feature_extraction.text import TfidfVectorizer
import logging
import pandas as pd
import scipy.sparse
import config
from config import PINECONE_API_KEY, TFIDF_INDEX_NAME, DATA_DIR
from tfidf_constants import TFIDF_CONFIG, RELEVANCE_THRESHOLDS

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

_tfidf_retriever_instance = None

def get_tfidf_retriever():
    global _tfidf_retriever_instance
    if _tfidf_retriever_instance is None:
        _tfidf_retriever_instance = TFIDFRetriever()
    return _tfidf_retriever_instance

class TFIDFRetriever:
    def __init__(self, data_dir: str = DATA_DIR):
        self.data_dir = data_dir
        self.vectorizer_path = os.path.join(data_dir, "tfidf_vectorizer.pkl")
        self.matrix_path = os.path.join(data_dir, "tfidf_matrix.npz")
        self.metadata_path = os.path.join(data_dir, "tfidf_metadata.json")

        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä–∞...")
        with open(self.vectorizer_path, "rb") as f:
            self._vectorizer = pickle.load(f)
        logger.info("TF-IDF –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")

        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã TF-IDF...")
        self.tfidf_matrix = scipy.sparse.load_npz(self.matrix_path)
        logger.info("TF-IDF –º–∞—Ç—Ä–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞...")
        with open(self.metadata_path, "r", encoding="utf-8") as f:
            metadata_json = json.load(f)

        # üëÄ –õ–æ–≥–∏—Ä—É–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
        logger.info(f"–¢–∏–ø tfidf_metadata.json: {type(metadata_json)}")

        # üí• –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        if isinstance(metadata_json, dict):
            if all(isinstance(v, dict) for v in metadata_json.values()):
                logger.warning("tfidf_metadata.json –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å–ª–æ–≤–∞—Ä–µ–π ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫")
                metadata_json = list(metadata_json.values())
            else:
                raise ValueError("tfidf_metadata.json –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º —Å–ª–æ–≤–∞—Ä–µ–π, –Ω–æ —ç—Ç–æ dict —Å–æ —Å–∫–∞–ª—è—Ä–∞–º–∏")

        if not isinstance(metadata_json, list):
            raise ValueError("tfidf_metadata.json –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º —Å–ª–æ–≤–∞—Ä–µ–π")

        logger.info(f"–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {json.dumps(metadata_json[0], ensure_ascii=False)[:200]}")
        self.metadata = pd.DataFrame(metadata_json)
        logger.info("–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

    @property
    def vectorizer(self):
        return self._vectorizer

    def get_tfidf_vector(self, text: str) -> list:
        try:
            if not hasattr(self.vectorizer, 'idf_'):
                raise ValueError("–í–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä –Ω–µ –æ–±—É—á–µ–Ω")
            return self.vectorizer.transform([text]).toarray()[0].tolist()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤–µ–∫—Ç–æ—Ä–∞: {e}")
            raise

    def retrieve_local_tfidf_only(self, query_text: str, top_k: int = 10) -> Dict[str, Any]:
        try:
            logger.info("–ó–∞–ø—É—Å–∫–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π TF-IDF –ø–æ–∏—Å–∫...")
            query_vector = self.vectorizer.transform([query_text])

            from sklearn.metrics.pairwise import cosine_similarity
            similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()

            top_indices = similarities.argsort()[::-1][:top_k]
            results = []
            for i in top_indices:
                score = similarities[i]
                row = self.metadata.iloc[i]
                results.append({
                    "score": float(score),
                    "metadata": {
                        "chunk_text": row["chunk_text"],
                        "topic": row.get("topic", None),
                        "source": row.get("source", ""),
                    }
                })

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(results)} –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ TF-IDF")
            return {"matches": results}

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º TF-IDF-–ø–æ–∏—Å–∫–µ: {e}")
            return {"matches": []}
