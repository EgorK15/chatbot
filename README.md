# Llama Chatbot

Чат-бот на базе модели Llama с веб-интерфейсом на Streamlit и интеграцией через LangChain.

## Возможности

- Чат с моделью Llama через OpenAI-совместимый API
- Поддержка нескольких чатов с возможностью переключения между ними
- Архивирование сообщений (Кнопка **"Очистить текущий чат"** архивирует (скрывает) все существующие сообщения в выбранном чате, позволяя новым сообщениям сохраняться и использоваться в контексте. Кнопка **"Удалить чат"** архивирует все сообщения и сам чат, удаляя его из видимого списка, но оставляя данные в базе для последующего анализа.)
- Структурированный вывод ответов модели с оценкой уверенности и источниками
- Настройка параметров модели и API через веб-интерфейс (ввод ключей, URL, модели и температуры)
- RAG с router и базой на основе pinecone. Возможность использовать свою базу данных (описана ниже). В случае отсутствия темы подходящей ллм отвечает сама.
- Рефлексия - повторяем 3 раза вопрос, чтобы получить более точный ответ
- gmail agent - поиск информации по 10 сообщениям в почте
- поиск статей в интернете по запросу, если не находим у нас
## Требования

- **Python 3.11** или выше
- **Pipenv** для управления зависимостями
- Доступ к API Llama через OpenAI-совместимый интерфейс
- **SQLite** (используется для хранения истории чатов и сообщений)
- Docker и Docker Compose (опционально)

## Установка и запуск без Docker

1. Клонируйте репозиторий или создайте новую директорию для проекта:

```bash
mkdir llama_chatbot
cd llama_chatbot
```

2. Установите зависимости с помощью Pipenv:

```bash
pipenv install
```

Или установите зависимости вручную:

```bash
pipenv install streamlit langchain langchain-openai openai
```

3. Активируйте виртуальное окружение:

```bash
pipenv shell
```

4. Запустите приложение Streamlit:

```bash
pipenv run streamlit run app.py
```

5. Откройте браузер по адресу http://localhost:8501

6. После запуска, введите в настройках API ключ и URL модели, чтобы начать общение с чат-ботом

## Запуск с Docker

1. Поместите настройки доступа в файл .env (см: .env.example)
  
2. Соберите и запустите контейнер с помощью Docker Compose:

```bash
docker-compose build
docker-compose up
```
Если совсем беды - запустить pipenv install 
pipenv run streamlit run app.py
2. Откройте браузер по адресу http://localhost:8501

3. После запуска, введите в настройках API ключ и URL модели, чтобы начать общение с чат-ботом
Или используйте Docker напрямую:


## Особенности интерфейса

- **Чаты**: Создавайте, переименовывайте и выбирайте чаты в боковой панели. Все сессии и их история сохраняются в базе данных, что позволяет восстанавливать их даже после перезапуска приложения
- **Настройки API**: В боковой панели можно настроить параметры подключения к модели (API ключ, URL, название модели, температура)
- **Структурированный вывод**: Включение этой опции позволяет получать от модели ответы в виде структурированного JSON, который отображается отдельно в интерфейсе
- **Архивирование сообщений**: можно архивировать чаты и сообщения

## Требования к API

Чат-бот предполагает, что вы имеете доступ к API, совместимому с OpenAI. Это может быть:

1. Локально запущенная модель Llama с API-сервером (например, через llama.cpp, llama-api или другое решение)
2. Внешний API-сервис, предоставляющий доступ к Llama

API должен быть совместим с форматом OpenAI для работы с langchain-openai.

## Настройка API через переменные окружения

Вы можете настроить API ключи через переменные окружения:

Для этого создайте файл `.env` в корне проекта по образу и подобию .env.example и заполните его своими данными
В поля INDEX_NAME и PINECONE_API_KEY - вставьте red-llama-bertopic и pcsk_2MHdUF_M8e8hZxWQN2NFvQ4CWhXvsyL7EwPzNpvmy7iYRCN8hpey5u1TvqHZJ89TjJmZUx (иначе вставьте в интерфейс)
Если хотите использовать свою базу, вставьте свои данные и запустите с ними vectorize.ipynb из соседней папки
Иначе введите их вручную в интерфейсе
## Возможные проблемы

- Если возникает ошибка при подключении к API, проверьте правильность URL и API ключа
- Убедитесь, что у вас установлены все необходимые зависимости
- Убедитесь, что вы в той папке
- Лучше создать env файл
- Проверти запуск докера
- При первом запуске в Docker может потребоваться некоторое время для загрузки зависимостей
- Необходимо иметь credentials.json в папке с проектом и добавить свою почту в гугл
