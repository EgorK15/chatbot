{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download ru_core_news_sm\n",
    "!pip install sentence-transformers\n",
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone API Key: pcsk_2MHdUF_M8e8hZxWQN2NFvQ4CWhXvsyL7EwPzNpvmy7iYRCN8hpey5u1TvqHZJ89TjJmZUx\n",
      "Pinecone index name: red-llama\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Получаем текущий рабочий каталог\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Строим путь на три уровня вверх\n",
    "config_path = os.path.join(current_dir, '..', '..', 'llama.config')\n",
    "\n",
    "# Нормализуем путь (убираем лишние '..' и т.д.)\n",
    "config_path = os.path.normpath(config_path)\n",
    "\n",
    "\n",
    "# Читаем файл\n",
    "with open(config_path, 'r') as file:\n",
    "    api_base = file.readline().strip()\n",
    "    my_model = file.readline().strip()\n",
    "    API_KEY = file.readline().strip()\n",
    "    YOUR_API_KEY = file.readline().strip()\n",
    "#    index_name = file.readline().strip()\n",
    "index_name = 'red-llama'\n",
    "\n",
    "# Выводим значения\n",
    "#print(f\"API Base: {api_base}\")\n",
    "#print(f\"My Model: {my_model}\")\n",
    "#print(f\"API Key: {API_KEY}\")\n",
    "print(f\"Pinecone API Key: {YOUR_API_KEY}\")\n",
    "print(f\"Pinecone index name: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Отключаем прогресс-бары для pandas\n",
    "tqdm.pandas(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 'red-llama' существует.\n",
      "Статистика индекса: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 557}},\n",
      " 'total_vector_count': 557,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Инициализация Pinecone\n",
    "pc = Pinecone(api_key=YOUR_API_KEY, environment=\"us-east1-gcp\")  # Укажите окружение\n",
    "\n",
    "# Имя индекса\n",
    "index_name = \"red-llama\"\n",
    "\n",
    "# Проверка существования индекса\n",
    "if index_name in pc.list_indexes().names():\n",
    "    print(f\"Индекс '{index_name}' существует.\")\n",
    "    \n",
    "    # Подключение к индексу\n",
    "    index = pc.Index(index_name)\n",
    "    \n",
    "    # Получение статистики индекса\n",
    "    index_stats = index.describe_index_stats()\n",
    "    print(\"Статистика индекса:\", index_stats)\n",
    "    \n",
    "    # Пример запроса данных (если нужно)\n",
    "    # query_response = index.query(\n",
    "    #     vector=[0.1] * 384,  # Пример вектора для запроса\n",
    "    #     top_k=5,  # Количество ближайших векторов\n",
    "    #     include_values=True  # Включить значения векторов в ответ\n",
    "    # )\n",
    "    # print(\"Результаты запроса:\", query_response)\n",
    "else:\n",
    "    print(f\"Индекс '{index_name}' не существует.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение данных с Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлечено 556 векторов из 568 запрошенных ID.\n",
      "Данные успешно сохранены в файл pinecone_fetch_data.json\n",
      "Всего извлечено векторов: 556\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "# 1. Инициализация Pinecone\n",
    "pc = Pinecone(api_key=YOUR_API_KEY, environment=\"us-east1-gcp\")  # Укажите окружение\n",
    "\n",
    "# 2. Подключение к индексу\n",
    "#index_name = \"your-index-name\"  # Замените на имя вашего индекса\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "\n",
    "\n",
    "# 3. Генерация списка всех ID\n",
    "start_id = 0\n",
    "end_id = 567\n",
    "all_ids = [f\"chunk_{i}\" for i in range(start_id, end_id + 1)]\n",
    "\n",
    "# 4. Извлечение данных с помощью метода fetch (один запрос)\n",
    "try:\n",
    "    fetch_response = index.fetch(ids=all_ids)\n",
    "    print(f\"Извлечено {len(fetch_response.vectors)} векторов из {len(all_ids)} запрошенных ID.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при извлечении данных: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 5. Обработка данных\n",
    "vectors = []\n",
    "for vector_id, vector_data in fetch_response.vectors.items():\n",
    "    vectors.append({\n",
    "        \"id\": vector_id,\n",
    "        \"vector\": vector_data.values,  # Значения вектора\n",
    "        \"metadata\": vector_data.metadata  # Метаданные\n",
    "    })\n",
    "\n",
    "# 6. Сохранение данных в JSON файл\n",
    "output_file = \"pinecone_fetch_data.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(vectors, f, indent=4)\n",
    "\n",
    "print(f\"Данные успешно сохранены в файл {output_file}\")\n",
    "print(f\"Всего извлечено векторов: {len(vectors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                             vector  \\\n",
      "0  chunk_338  [-0.0225879718, 0.0184257105, -0.0145661086, -...   \n",
      "1  chunk_161  [0.025534546, 0.0278284252, -0.0194324423, 0.0...   \n",
      "2  chunk_277  [-0.0209172536, 0.0307390876, -0.0386536568, -...   \n",
      "3  chunk_175  [0.0294892043, -0.0505454838, 0.0347524546, -0...   \n",
      "4  chunk_160  [-0.0361339115, -0.0174505413, -0.0816515312, ...   \n",
      "\n",
      "                                            metadata  \n",
      "0  {'answer': 'По нормативным значениям АК (автом...  \n",
      "1  {'answer': 'Это инъекции, которые разглаживают...  \n",
      "2  {'answer': 'Первый ресторан в России со звездо...  \n",
      "3  {'answer': 'The Telegram development team is b...  \n",
      "4  {'answer': 'Начинайте с низкой концентрации и ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. Загрузка данных из JSON файла\n",
    "output_file = \"pinecone_fetch_data.json\"\n",
    "with open(output_file, \"r\") as f:\n",
    "    vectors = json.load(f)\n",
    "\n",
    "# 2. Преобразование в DataFrame\n",
    "df = pd.DataFrame(vectors)\n",
    "\n",
    "# 3. Вывод первых нескольких строк DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отсутствующие ID: ['chunk_380', 'chunk_381', 'chunk_382', 'chunk_383', 'chunk_384', 'chunk_385', 'chunk_386', 'chunk_387', 'chunk_388', 'chunk_389', 'chunk_390', 'chunk_391']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "# Пример DataFrame\n",
    "data = {\n",
    "    \"id\": [\"chunk_338\", \"chunk_161\", \"chunk_277\", \"chunk_175\"],\n",
    "    \"vector\": [\n",
    "        [-0.0225879718, 0.0184257105, -0.0145661086],\n",
    "        [0.025534546, 0.0278284252, -0.0194324423],\n",
    "        [-0.0209172536, 0.0307390876, -0.0386536568],\n",
    "        [0.0294892043, -0.0505454838, 0.0347524546]\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "'''\n",
    "# 1. Создайте список всех ожидаемых ID\n",
    "start_id = 0\n",
    "end_id = 567\n",
    "all_ids = [f\"chunk_{i}\" for i in range(start_id, end_id + 1)]\n",
    "\n",
    "# 2. Извлеките список ID из DataFrame\n",
    "present_ids = df[\"id\"].tolist()\n",
    "\n",
    "# 3. Найдите отсутствующие ID\n",
    "missing_ids = set(all_ids) - set(present_ids)\n",
    "\n",
    "# 4. Выведите результат\n",
    "print(f\"Отсутствующие ID: {sorted(missing_ids)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсутствующие ID: ['chunk_380', 'chunk_381', 'chunk_382', 'chunk_383', 'chunk_384', 'chunk_385', 'chunk_386', 'chunk_387', 'chunk_388', 'chunk_389', 'chunk_390', 'chunk_391']\n",
    "\n",
    "\n",
    "Вектор chunk_407 содержит только нули и будет удален.\n",
    "Вектор chunk_557 содержит только нули и будет удален.\n",
    "Вектор chunk_444 содержит только нули и будет удален.\n",
    "Вектор chunk_394 содержит только нули и будет удален.\n",
    "Вектор chunk_397 содержит только нули и будет удален.\n",
    "Вектор chunk_415 содержит только нули и будет удален.\n",
    "Вектор chunk_546 содержит только нули и будет удален.\n",
    "Вектор chunk_405 содержит только нули и будет удален.\n",
    "Вектор chunk_455 содержит только нули и будет удален.\n",
    "Вектор chunk_410 содержит только нули и будет удален.\n",
    "Загружено 50 векторов\n",
    "Загружено 100 векторов\n",
    "Загружено 150 векторов\n",
    "Загружено 200 векторов\n",
    "Загружено 250 векторов\n",
    "Загружено 300 векторов\n",
    "Загружено 350 векторов\n",
    "Загружено 400 векторов\n",
    "Загружено 450 векторов\n",
    "Загружено 500 векторов\n",
    "Загружено 546 векторов\n",
    "Данные успешно загружены в Pinecone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             id                                             vector  \\\n",
       "0    chunk_338  [-0.0225879718, 0.0184257105, -0.0145661086, -...   \n",
       "1    chunk_161  [0.025534546, 0.0278284252, -0.0194324423, 0.0...   \n",
       "2    chunk_277  [-0.0209172536, 0.0307390876, -0.0386536568, -...   \n",
       "3    chunk_175  [0.0294892043, -0.0505454838, 0.0347524546, -0...   \n",
       "4    chunk_160  [-0.0361339115, -0.0174505413, -0.0816515312, ...   \n",
       "..         ...                                                ...   \n",
       "551  chunk_554  [-0.00727135316, -0.0198816322, -0.0630982593,...   \n",
       "552  chunk_245  [-0.00947351288, 0.0156911984, -0.00623399531,...   \n",
       "553  chunk_286  [0.024843974, 0.00707773, -0.0402551107, 0.005...   \n",
       "554  chunk_105  [-0.00596816931, 0.0651620179, 0.0414247811, 0...   \n",
       "555  chunk_337  [0.0343624614, 0.0673869103, 0.0294149406, -0....   \n",
       "\n",
       "                                              metadata  \n",
       "0    {'answer': 'По нормативным значениям АК (автом...  \n",
       "1    {'answer': 'Это инъекции, которые разглаживают...  \n",
       "2    {'answer': 'Первый ресторан в России со звездо...  \n",
       "3    {'answer': 'The Telegram development team is b...  \n",
       "4    {'answer': 'Начинайте с низкой концентрации и ...  \n",
       "..                                                 ...  \n",
       "551  {'answer': 'Нет ответа', 'category': 'companie...  \n",
       "552  {'answer': 'В World Class 3.0 появилась уникал...  \n",
       "553  {'answer': 'Испытательный срок устанавливается...  \n",
       "554  {'answer': 'Они не любят оставаться одни надол...  \n",
       "555  {'answer': 'Габариты должны соответствовать ка...  \n",
       "\n",
       "[556 rows x 3 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                             vector  \\\n",
      "0  chunk_338  [-0.0225879718, 0.0184257105, -0.0145661086, -...   \n",
      "1  chunk_161  [0.025534546, 0.0278284252, -0.0194324423, 0.0...   \n",
      "2  chunk_277  [-0.0209172536, 0.0307390876, -0.0386536568, -...   \n",
      "3  chunk_175  [0.0294892043, -0.0505454838, 0.0347524546, -0...   \n",
      "4  chunk_160  [-0.0361339115, -0.0174505413, -0.0816515312, ...   \n",
      "\n",
      "                                            metadata  \\\n",
      "0  {'answer': 'По нормативным значениям АК (автом...   \n",
      "1  {'answer': 'Это инъекции, которые разглаживают...   \n",
      "2  {'answer': 'Первый ресторан в России со звездо...   \n",
      "3  {'answer': 'The Telegram development team is b...   \n",
      "4  {'answer': 'Начинайте с низкой концентрации и ...   \n",
      "\n",
      "                                          chunk_text  \n",
      "0  9. Как рассчитываются нагрузки от транспортных...  \n",
      "1  Что такое ботокс для лица? Это инъекции, котор...  \n",
      "2  Какой ресторан и когда в России получил первую...  \n",
      "3  Where is Telegram based? The Telegram developm...  \n",
      "4  Как использовать ретинол? Начинайте с низкой к...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Пример DataFrame\n",
    "data = {\n",
    "    \"id\": [\"chunk_338\", \"chunk_161\", \"chunk_277\", \"chunk_175\"],\n",
    "    \"vector\": [\n",
    "        [-0.0225879718, 0.0184257105, -0.0145661086],\n",
    "        [0.025534546, 0.0278284252, -0.0194324423],\n",
    "        [-0.0209172536, 0.0307390876, -0.0386536568],\n",
    "        [0.0294892043, -0.0505454838, 0.0347524546]\n",
    "    ],\n",
    "    \"metadata\": [\n",
    "        {\"chunk_text\": \"Text 1\", \"other_key\": \"value1\"},\n",
    "        {\"chunk_text\": \"Text 2\", \"other_key\": \"value2\"},\n",
    "        {\"chunk_text\": \"Text 3\", \"other_key\": \"value3\"},\n",
    "        {\"chunk_text\": \"Text 4\", \"other_key\": \"value4\"}\n",
    "    ]\n",
    "}\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Извлечение chunk_text из metadata\n",
    "df[\"chunk_text\"] = df[\"metadata\"].apply(lambda x: x.get(\"chunk_text\"))\n",
    "\n",
    "# Вывод первых строк DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка чанков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                         chunk_text   00  000  \\\n",
      "0    chunk_338  9. Как рассчитываются нагрузки от транспортных...  0.0  0.0   \n",
      "1    chunk_161  Что такое ботокс для лица? Это инъекции, котор...  0.0  0.0   \n",
      "2    chunk_277  Какой ресторан и когда в России получил первую...  0.0  0.0   \n",
      "3    chunk_175  Where is Telegram based? The Telegram developm...  0.0  0.0   \n",
      "4    chunk_160  Как использовать ретинол? Начинайте с низкой к...  0.0  0.0   \n",
      "..         ...                                                ...  ...  ...   \n",
      "551  chunk_554  \\nWas the Group's revolving credit facility (R...  0.0  0.0   \n",
      "552  chunk_245  Чем отличается мобильное приложение World Clas...  0.0  0.0   \n",
      "553  chunk_286  7. Как оформляется испытательный срок при прие...  0.0  0.0   \n",
      "554  chunk_105  Как французский бульдог относится к одиночеств...  0.0  0.0   \n",
      "555  chunk_337  8. Какие требования к габаритам мостов указаны...  0.0  0.0   \n",
      "\n",
      "     000kg  000oz  000to  001  003  004  ...  являющихся  языком  яиц  яйца  \\\n",
      "0      0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "1      0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "2      0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "3      0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "4      0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "..     ...    ...    ...  ...  ...  ...  ...         ...     ...  ...   ...   \n",
      "551    0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "552    0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "553    0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "554    0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "555    0.0    0.0    0.0  0.0  0.0  0.0  ...         0.0     0.0  0.0   0.0   \n",
      "\n",
      "     январь  япония  японский      ярче  ятс  ячейки  \n",
      "0       0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "1       0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "2       0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "3       0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "4       0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "..      ...     ...       ...       ...  ...     ...  \n",
      "551     0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "552     0.0     0.0       0.0  0.102361  0.0     0.0  \n",
      "553     0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "554     0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "555     0.0     0.0       0.0  0.000000  0.0     0.0  \n",
      "\n",
      "[556 rows x 8074 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Пример DataFrame\n",
    "data = {\n",
    "    \"id\": [\"chunk_1\", \"chunk_2\", \"chunk_3\", \"chunk_4\"],\n",
    "    \"chunk_text\": [\n",
    "        \"This is the first document.\",\n",
    "        \"This document is the second document.\",\n",
    "        \"And this is the third one.\",\n",
    "        \"Is this the first document?\"\n",
    "    ]\n",
    "}\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Инициализация TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Преобразование текстов в TF-IDF матрицу\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"chunk_text\"])\n",
    "\n",
    "# 3. Преобразование матрицы в DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# 4. Добавление ID к результату\n",
    "tfidf_df.insert(0, \"id\", df[\"id\"])\n",
    "tfidf_df.insert(1, \"chunk_text\", df[\"chunk_text\"])\n",
    "\n",
    "# Вывод результата\n",
    "print(tfidf_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Загрузка векторов на Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556, 8074)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df.shape)  # (количество строк, количество столбцов)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вектор chunk_407 содержит только нули и будет удален.\n",
      "Вектор chunk_557 содержит только нули и будет удален.\n",
      "Вектор chunk_444 содержит только нули и будет удален.\n",
      "Вектор chunk_394 содержит только нули и будет удален.\n",
      "Вектор chunk_397 содержит только нули и будет удален.\n",
      "Вектор chunk_415 содержит только нули и будет удален.\n",
      "Вектор chunk_546 содержит только нули и будет удален.\n",
      "Вектор chunk_405 содержит только нули и будет удален.\n",
      "Вектор chunk_455 содержит только нули и будет удален.\n",
      "Вектор chunk_410 содержит только нули и будет удален.\n",
      "Загружено 50 векторов\n",
      "Загружено 100 векторов\n",
      "Загружено 150 векторов\n",
      "Загружено 200 векторов\n",
      "Загружено 250 векторов\n",
      "Загружено 300 векторов\n",
      "Загружено 350 векторов\n",
      "Загружено 400 векторов\n",
      "Загружено 450 векторов\n",
      "Загружено 500 векторов\n",
      "Загружено 546 векторов\n",
      "Данные успешно загружены в Pinecone!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Инициализация Pinecone\n",
    "pc = Pinecone(api_key=YOUR_API_KEY, environment=\"us-east1-gcp\")  # Укажите окружение\n",
    "\n",
    "tf_idf_index_name = \"red-llama-tf-idf\"\n",
    "\n",
    "# 2. Подключение к индексу\n",
    "index = pc.Index(tf_idf_index_name)\n",
    "# 384\n",
    "# 8074 - 2\n",
    "\n",
    "# 2. Подготовка данных\n",
    "# Предположим, что tfidf_df содержит столбцы \"id\", \"chunk_text\" и TF-IDF векторы\n",
    "vectors = []\n",
    "for _, row in tfidf_df.iterrows():\n",
    "    vector_id = row[\"id\"]  # Уникальный идентификатор\n",
    "    vector_values = row.drop([\"id\", \"chunk_text\"]).tolist()  # TF-IDF вектор\n",
    "    metadata = {\"chunk_text\": row[\"chunk_text\"]}  # Метаданные (например, текст)\n",
    "    vectors.append((vector_id, vector_values, metadata))\n",
    "\n",
    "# 3. Удаление нулевых векторов\n",
    "filtered_vectors = []\n",
    "for vector_id, vector_values, metadata in vectors:\n",
    "    if any(vector_values):  # Проверка, есть ли хотя бы одно ненулевое значение\n",
    "        filtered_vectors.append((vector_id, vector_values, metadata))\n",
    "    else:\n",
    "        print(f\"Вектор {vector_id} содержит только нули и будет удален.\")\n",
    "\n",
    "# 4. Загрузка данных по пакетам\n",
    "batch_size = 50  # Уменьшите размер пакета\n",
    "for i in range(0, len(filtered_vectors), batch_size):\n",
    "    batch = filtered_vectors[i:i + batch_size]\n",
    "    index.upsert(batch)\n",
    "    print(f\"Загружено {i + len(batch)} векторов\")\n",
    "\n",
    "# 3. Загрузка данных в Pinecone\n",
    "# index.upsert(vectors)\n",
    "\n",
    "print(\"Данные успешно загружены в Pinecone!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение первых записей в JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение первых записей в JSON\n",
    "tfidf_df.head(1).to_json(\"tfidf_vectors.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и сохранение векторизатора TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обученный TfidfVectorizer сохранен.\n",
      "Загруженный TfidfVectorizer: TfidfVectorizer()\n",
      "ID: chunk_547\n",
      "Сходство: 0.862579823\n",
      "Текст: What was Brave Bison's total revenue for 2022?\n",
      "£31.7 million\n",
      "\n",
      "---\n",
      "ID: chunk_552\n",
      "Сходство: 0.346977443\n",
      "Текст: \n",
      "What was the total number of monthly views generated by Brave Bison Media Network?\n",
      "Over 1 billion monthly views\n",
      "\n",
      "---\n",
      "ID: chunk_551\n",
      "Сходство: 0.326618254\n",
      "Текст: \n",
      "What percentage of Brave Bison staff work on a hybrid basis?\n",
      "Over 50%\n",
      "\n",
      "---\n",
      "ID: chunk_565\n",
      "Сходство: 0.316588402\n",
      "Текст: \n",
      "\n",
      "8. What was the total assets as of June 30, 2022?\n",
      "Answer: $22,929,553\n",
      "\n",
      "\n",
      "---\n",
      "ID: chunk_560\n",
      "Сходство: 0.298785508\n",
      "Текст: \n",
      "\n",
      "3. What was the net profit for 2022?\n",
      "Answer: $491,955\n",
      "\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "tf_idf_index_name = \"red-llama-tf-idf\"\n",
    "\n",
    "# 1. Инициализация Pinecone\n",
    "pc = Pinecone(api_key=YOUR_API_KEY)\n",
    "index = pc.Index(tf_idf_index_name)\n",
    "\n",
    "\n",
    "# 3. Обучите TfidfVectorizer на ваших данных\n",
    "\n",
    "corpus = df[\"chunk_text\"].tolist()\n",
    "\n",
    "# Обучение TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)  # Обучаем вектор на корпусе текстов\n",
    "\n",
    "\n",
    "# Сохранение обученного вектора\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"Обученный TfidfVectorizer сохранен.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка векторизатора TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загруженный TfidfVectorizer: TfidfVectorizer()\n",
      "ID: chunk_547\n",
      "Сходство: 0.862579823\n",
      "Текст: What was Brave Bison's total revenue for 2022?\n",
      "£31.7 million\n",
      "\n",
      "---\n",
      "ID: chunk_552\n",
      "Сходство: 0.346977443\n",
      "Текст: \n",
      "What was the total number of monthly views generated by Brave Bison Media Network?\n",
      "Over 1 billion monthly views\n",
      "\n",
      "---\n",
      "ID: chunk_551\n",
      "Сходство: 0.326618254\n",
      "Текст: \n",
      "What percentage of Brave Bison staff work on a hybrid basis?\n",
      "Over 50%\n",
      "\n",
      "---\n",
      "ID: chunk_565\n",
      "Сходство: 0.316588402\n",
      "Текст: \n",
      "\n",
      "8. What was the total assets as of June 30, 2022?\n",
      "Answer: $22,929,553\n",
      "\n",
      "\n",
      "---\n",
      "ID: chunk_560\n",
      "Сходство: 0.298785508\n",
      "Текст: \n",
      "\n",
      "3. What was the net profit for 2022?\n",
      "Answer: $491,955\n",
      "\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 2. Подготовка вектора запроса\n",
    "query_text = \"What was Brave Bison's total revenue for 2022?\"  # Замените на ваш текст\n",
    "\n",
    "\n",
    "# Загрузка обученного TfidfVectorizer\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "\n",
    "\n",
    "vectorizer = loaded_vectorizer\n",
    "\n",
    "print(\"Загруженный TfidfVectorizer:\", loaded_vectorizer)\n",
    "\n",
    "# 4. Преобразуйте текст запроса в вектор\n",
    "query_vector = vectorizer.transform([query_text]).toarray().flatten().tolist()\n",
    "\n",
    "# 5. Выполнение поиска\n",
    "results = index.query(\n",
    "    vector=query_vector,  # Вектор запроса\n",
    "    top_k=5,  # Количество ближайших векторов\n",
    "    include_metadata=True  # Включить метаданные в результаты\n",
    ")\n",
    "\n",
    "# 6. Обработка результатов\n",
    "for match in results[\"matches\"]:\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Сходство: {match['score']}\")\n",
    "    print(f\"Текст: {match['metadata']['chunk_text']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q_A_rectifier_technologies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q_A_Brave_Bison.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: chunk_451\n",
      "Сходство: 0.41920352\n",
      "Текст: \n",
      "7\tIs Starvest plc’s business described as inherently low risk?\t\n",
      "No\n",
      "\n",
      "---\n",
      "ID: chunk_452\n",
      "Сходство: 0.414533108\n",
      "Текст: \n",
      "8\tDoes Starvest plc engage with stakeholders on a regular basis?\t\n",
      "Yes\n",
      "\n",
      "---\n",
      "ID: chunk_447\n",
      "Сходство: 0.368950784\n",
      "Текст: \n",
      "3\tIs the company Starvest plc involved in any operating activities beyond its investment holdings?\t\n",
      "No\n",
      "\n",
      "---\n",
      "ID: chunk_448\n",
      "Сходство: 0.349774748\n",
      "Текст: \n",
      "4\tDid Starvest plc make any charitable or political donations during the year?\t\n",
      "No\n",
      "\n",
      "---\n",
      "ID: chunk_454\n",
      "Сходство: 0.327684224\n",
      "Текст: \n",
      "10\tАre all Directors of Starvest plc required to attend board meetings at least quarterly?\t\n",
      "Yes\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 2. Подготовка вектора запроса\n",
    "query_text = \"Starvest plc?\"  # Замените на ваш текст\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Преобразуйте текст запроса в вектор\n",
    "query_vector = vectorizer.transform([query_text]).toarray().flatten().tolist()\n",
    "\n",
    "# 5. Выполнение поиска\n",
    "results = index.query(\n",
    "    vector=query_vector,  # Вектор запроса\n",
    "    top_k=5,  # Количество ближайших векторов\n",
    "    include_metadata=True  # Включить метаданные в результаты\n",
    ")\n",
    "\n",
    "# 6. Обработка результатов\n",
    "for match in results[\"matches\"]:\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Сходство: {match['score']}\")\n",
    "    print(f\"Текст: {match['metadata']['chunk_text']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic id: [-2], Topic: Starvest plc, Category: companies\n",
      "Topic id: [-2], Topic: Brave Bison, Category: companies\n",
      "Topic id: [-2], Topic: Rectifier Technologies Ltd, Category: companies\n",
      "Topic id: [-1], Topic: Высшее образование, Category: Социальное обеспечение\n",
      "Topic id: [0], Topic: Французский бульдог, Category: Собаководство\n",
      "Topic id: [3], Topic: Уход за кожей, Category: Косметика\n",
      "Topic id: [4], Topic: СП35.13330.2010, Category: СНиП\n",
      "Topic id: [1], Topic: rmr (red_mad_robot), Category: companies\n",
      "Topic id: [2], Topic: Telegram, Category: companies\n",
      "Topic id: [5], Topic: Michelin, Category: companies\n",
      "Topic id: [6], Topic: Трудовой кодекс РФ, Category: Законодательство\n",
      "Topic id: [7], Topic: World Class, Category: companies\n",
      "Topic id: [8], Topic: Оплата услуг, Category: Оплата услуг\n"
     ]
    }
   ],
   "source": [
    "new_keys = {\n",
    "    -2: -2,\n",
    "    -1: -1,\n",
    "    0: 0,\n",
    "    1: 3,\n",
    "    2: 4,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "    5: 5,\n",
    "    6: 6,\n",
    "    7: 7,\n",
    "    8: 8\n",
    "}\n",
    "topics = {\n",
    "#    -2: 'a company from companies',\n",
    "    -1: \"Высшее образование\",\n",
    "    0: \"Французский бульдог\",\n",
    "    1: \"rmr (red_mad_robot)\",\n",
    "    2: \"Telegram\",\n",
    "    3: \"Уход за кожей\",\n",
    "    4: \"СП35.13330.2010\",\n",
    "    5: \"Michelin\",\n",
    "    6: \"Трудовой кодекс РФ\",\n",
    "    7: \"World Class\",\n",
    "    8: \"Оплата услуг\"\n",
    "}\n",
    "categories = {\n",
    "    -2: \"companies\",\n",
    "    -1: \"Социальное обеспечение\",\n",
    "    0: \"Собаководство\",\n",
    "    1: \"companies\",\n",
    "    2: \"companies\",\n",
    "    3: \"Косметика\",\n",
    "    4: \"СНиП\",\n",
    "    5: \"companies\",\n",
    "    6: \"Законодательство\",\n",
    "    7: \"companies\",\n",
    "    8: \"Оплата услуг\"\n",
    "}\n",
    "companies = [\n",
    "    'Starvest plc',\n",
    "    'Brave Bison',\n",
    "    'Rectifier Technologies Ltd'\n",
    "]\n",
    "\n",
    "keys = list(topics.keys())  # Предполагаем, что все три словаря имеют одинаковые ключи\n",
    "\n",
    "for key in new_keys:\n",
    "    if (key == -2):\n",
    "        for company in companies:\n",
    "            topic_name = company\n",
    "            category = categories[new_keys[key]]\n",
    "            print(f\"Topic id: {[new_keys[key]]}, Topic: {topic_name}, Category: {category}\")\n",
    "    else:\n",
    "        topic_name = topics[new_keys[key]]\n",
    "        category = categories[new_keys[key]]\n",
    "        print(f\"Topic id: {[new_keys[key]]}, Topic: {topic_name}, Category: {category}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
